{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required installs for training and running the ML model:\n",
    "# !pip install -U pandas\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install -U numpy\n",
    "# !pip install -U matplotlib\n",
    "# !pip install -U joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc574f50",
   "metadata": {},
   "source": [
    "Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02faa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and prepare dataset\n",
    "df = pd.read_csv('sample_data2.csv')  # Load sensor dataset from CSV\n",
    "\n",
    "# Encode activity labels (string â†’ integer codes)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Activity_encoded'] = label_encoder.fit_transform(df['Activity'])\n",
    "\n",
    "# 2. Sliding window parameters\n",
    "window_size = 200  # Number of samples per analysis window\n",
    "step_size = 50     # Step size between windows\n",
    "\n",
    "# Lists to store extracted features and labels\n",
    "features_list = []\n",
    "labels = []\n",
    "\n",
    "# Sensor columns used for feature extraction\n",
    "sensor_cols = [\n",
    "    'Roll1', 'Pitch1', 'Yaw1',\n",
    "    'Roll2', 'Pitch2', 'Yaw2',\n",
    "    'FRS', 'EMG1'\n",
    "]\n",
    "\n",
    "# 3. Feature extraction function\n",
    "def extract_features_from_window(window):\n",
    "    \"\"\"\n",
    "    Extracts statistical features from each sensor column in a given time window.\n",
    "    Features per column:\n",
    "      - Mean\n",
    "      - Standard deviation\n",
    "      - Minimum value\n",
    "      - Maximum value\n",
    "      - Root Mean Square (RMS)\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    for col in sensor_cols:\n",
    "        data = window[col].values\n",
    "        feats.extend([\n",
    "            np.mean(data),                    # Mean\n",
    "            np.std(data),                     # Standard deviation\n",
    "            np.min(data),                     # Minimum\n",
    "            np.max(data),                     # Maximum\n",
    "            np.sqrt(np.mean(data**2))         # RMS\n",
    "        ])\n",
    "    return feats\n",
    "\n",
    "# 4. Apply sliding window to extract features and labels\n",
    "for start in range(0, len(df) - window_size, step_size):\n",
    "    window = df.iloc[start:start + window_size]\n",
    "    feats = extract_features_from_window(window)\n",
    "    features_list.append(feats)\n",
    "    labels.append(window['Activity_encoded'].mode()[0])  # Majority vote label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2843f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity\n",
      "standing      8914\n",
      "walking       6998\n",
      "downstairs    4921\n",
      "upstairs      4919\n",
      "sitting       3946\n",
      "sit_stand     3170\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Activity'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fece89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): 'downstairs', np.int64(1): 'sit_stand', np.int64(2): 'sitting', np.int64(3): 'standing', np.int64(4): 'upstairs', np.int64(5): 'walking', np.int64(6): nan}\n"
     ]
    }
   ],
   "source": [
    "print(dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fe01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  downstairs       1.00      1.00      1.00        22\n",
      "   sit_stand       1.00      1.00      1.00        12\n",
      "     sitting       1.00      0.93      0.97        15\n",
      "    standing       0.90      1.00      0.95        27\n",
      "    upstairs       1.00      1.00      1.00        27\n",
      "     walking       1.00      0.93      0.96        28\n",
      "\n",
      "    accuracy                           0.98       131\n",
      "   macro avg       0.98      0.98      0.98       131\n",
      "weighted avg       0.98      0.98      0.98       131\n",
      "\n",
      "Confusion Matrix:\n",
      " [[22  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0]\n",
      " [ 0  0 14  1  0  0]\n",
      " [ 0  0  0 27  0  0]\n",
      " [ 0  0  0  0 27  0]\n",
      " [ 0  0  0  2  0 26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert lists to NumPy arrays for model input\n",
    "X = np.array(features_list)  # Feature matrix\n",
    "y = np.array(labels)         # Encoded activity labels\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Get the unique labels present in the test set\n",
    "unique_labels = np.unique(y_test)\n",
    "\n",
    "# Convert encoded labels back to their original activity names\n",
    "target_names = label_encoder.inverse_transform(unique_labels)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    labels=unique_labels,\n",
    "    target_names=target_names\n",
    "))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    labels=unique_labels\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe48cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.94656489 1.         0.97709924 1.         0.96153846]\n",
      "Average accuracy: 0.9770405167351732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation using the same Random Forest classifier\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print the individual fold scores\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "print(\"Average accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cfbfc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV scores: [0.99236641 0.97709924 0.98473282 0.99236641 0.96923077]\n",
      "Average accuracy: 0.9831591309453904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# StratifiedKFold ensures each fold has the same class distribution as the whole dataset\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation using stratified folds\n",
    "scores = cross_val_score(clf, X, y, cv=skf)\n",
    "\n",
    "# Print results\n",
    "print(\"Stratified CV scores:\", scores)\n",
    "print(\"Average accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123cad5",
   "metadata": {},
   "source": [
    "Real-Time Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1695eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Random Forest model to a file\n",
    "joblib.dump(clf, \"rf_model.pkl\")\n",
    "\n",
    "# Save the label encoder so we can decode predictions later\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce26b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SerialException",
     "evalue": "could not open port 'COM5': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSerialException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m label_encoder = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mlabel_encoder.pkl\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Make sure you saved this earlier!\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Connect to Teensy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m ser = \u001b[43mserial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSerial\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCOM5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m115200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Rolling buffer (1 second = 200 samples @ 200 Hz)\u001b[39;00m\n\u001b[32m     15\u001b[39m buffer = deque(maxlen=\u001b[32m200\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grego\\anaconda3\\envs\\Wearable_Sensors\\Lib\\site-packages\\serial\\serialwin32.py:33\u001b[39m, in \u001b[36mSerial.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m._overlapped_read = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m._overlapped_write = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSerial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grego\\anaconda3\\envs\\Wearable_Sensors\\Lib\\site-packages\\serial\\serialutil.py:244\u001b[39m, in \u001b[36mSerialBase.__init__\u001b[39m\u001b[34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[39m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33munexpected keyword arguments: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(kwargs))\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grego\\anaconda3\\envs\\Wearable_Sensors\\Lib\\site-packages\\serial\\serialwin32.py:64\u001b[39m, in \u001b[36mSerial.open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._port_handle == win32.INVALID_HANDLE_VALUE:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m._port_handle = \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m# 'cause __del__ is called anyway\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[33m\"\u001b[39m\u001b[33mcould not open port \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.portstr, ctypes.WinError()))\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m._overlapped_read = win32.OVERLAPPED()\n",
      "\u001b[31mSerialException\u001b[39m: could not open port 'COM5': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)"
     ]
    }
   ],
   "source": [
    "import serial\n",
    "from collections import deque\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Suppress non-critical warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load trained Random Forest model and Label Encoder\n",
    "# ---------------------------------------------------------\n",
    "model = joblib.load(\"rf_model.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\") \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Connect to Teensy via serial port\n",
    "#   - Replace \"COM5\" with the correct port for your system\n",
    "# ---------------------------------------------------------\n",
    "ser = serial.Serial(\"COM5\", 115200, timeout=1)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Buffers for real-time processing\n",
    "# ---------------------------------------------------------\n",
    "buffer = deque(maxlen=200)           # Holds the last 200 sensor samples\n",
    "prediction_history = deque(maxlen=5) # Holds the last 5 predictions (for smoothing)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Feature extraction for one time window\n",
    "# ---------------------------------------------------------\n",
    "def extract_features(buffer_np):\n",
    "    \"\"\"\n",
    "    Extracts statistical features from each column in the sensor data buffer.\n",
    "    Features per column:\n",
    "        - Mean\n",
    "        - Standard deviation\n",
    "        - Minimum\n",
    "        - Maximum\n",
    "        - Root Mean Square (RMS)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for i in range(buffer_np.shape[1]):  # Loop over sensor columns\n",
    "        col = buffer_np[:, i]\n",
    "        features.extend([\n",
    "            np.mean(col),                   # Mean\n",
    "            np.std(col),                    # Standard deviation\n",
    "            np.min(col),                    # Minimum\n",
    "            np.max(col),                    # Maximum\n",
    "            np.sqrt(np.mean(col**2))        # RMS\n",
    "        ])\n",
    "    return np.array(features).reshape(1, -1)  # Return as 2D array for model\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Main loop: read serial data, predict, and print result\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    while True:\n",
    "        # Read one line from serial and split into sensor values\n",
    "        line = ser.readline().decode(\"utf-8\").strip()\n",
    "        parts = line.split(\"\\t\")\n",
    "        \n",
    "        # Expecting exactly 8 sensor readings per line\n",
    "        if len(parts) != 8:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Convert sensor readings to floats and add to buffer\n",
    "            features = list(map(float, parts))\n",
    "            buffer.append(features)\n",
    "        except ValueError:\n",
    "            continue  # Skip lines with invalid data\n",
    "\n",
    "        # Once buffer is full, make a prediction\n",
    "        if len(buffer) == buffer.maxlen:\n",
    "            buffer_np = np.array(buffer)\n",
    "            feat_vector = extract_features(buffer_np)\n",
    "            \n",
    "            # Predict using the trained model\n",
    "            pred = model.predict(feat_vector)[0]\n",
    "            prediction_history.append(pred)\n",
    "    \n",
    "            # Majority vote smoothing over last N predictions\n",
    "            smoothed_pred = max(set(prediction_history), key=prediction_history.count)\n",
    "            \n",
    "            # Decode numeric prediction back to label\n",
    "            label = label_encoder.inverse_transform([smoothed_pred])[0]\n",
    "            print(\"Prediction:\", label)\n",
    "\n",
    "# Graceful exit on Ctrl+C\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "\n",
    "# Handle other exceptions\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Always close the serial connection\n",
    "finally:\n",
    "    ser.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wearable_Sensors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
